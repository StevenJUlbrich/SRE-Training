# Chapter 9 â€“ Observability Deep Dive
---

## Chapter Overview  

Modern banking outages rarely shout in one dimension. A p99 latency graph flickers red, yet CPU hovers green and logs spew nothing but INFO. Meanwhile thousands of forex customers hammer â€œretry,â€ inflating traffic statistics until every panel glows an unsorted rainbow of misery.  Mere â€œmonitoringâ€ canâ€™t diagnose that chaos; you need **observability**â€”the art of stitching metrics, traces, logs, and even business-domain events into a single narrative that points a bright arrow at root cause.

This chapter is where we tighten that stitch.  **Ava Kimani** recruits **Raj Patel**, a former data-platform engineer who once debugged petabyte Hadoop spills with nothing but grep.  Together they will thread OpenTelemetry through Java, Go, and Python micro-services, tag spans with customer and transaction IDs, and push exemplars into Prometheus histograms so Grafana panels can hyperlink straight to a guilty trace.

We will begin by revisiting the **Signal Triad**â€”metrics, logs, tracesâ€”and their two canonical methodologies: **RED** (Rate - Errors - Duration) and **USE** (Utilisation - Saturation - Errors).  Next, youâ€™ll auto-instrument a Go API, then manually enrich a critical span with `transaction_type=FOREX` so we can slice latency by business context.  You will audit label cardinality to stop engineers shipping 10 million time-series by accident, and youâ€™ll learn how **exemplars** transform a dull p99 line into an interactive story.

Halfway through, we add a â€œfourth signalâ€: Kafka-published **business events** such as `FX_CONVERSION_COMPLETE`.  By overlaying event spikes on traces, Raj uncovers patterns that pure telemetry missesâ€”like a wave of ZARâ†’KES conversions that hammer a downstream rate oracle.  We finish with cost controls: tail-sampling pipelines, adaptive exemplars, and a quarterly â€œobservability debtâ€ scorecard that keeps the telemetry bill under control while preserving SLO clarity.

By the end of this deep dive, a burn-rate alert will show you **which** customer flow is failing, **why** it fails, **where** in the code, and **how long** before trust evaporatesâ€”all in a single click.

---

## ğŸ¯ Learning Objective  
Instrument OTEL across three languages, export metrics/traces/logs to Prometheus + Tempo + Loki, build exemplar-rich dashboards, and craft three-signal correlations that surface root cause in â‰¤ 60 seconds.

## âœ… Takeaway  
Observability is not more data; it is the shortest path from SLO breach to root cause.

## ğŸš¦ Applied Example  <!-- preview, full version will reach â‰¥ 150 w -->
Fund-transfer latency spikesâ€”but only for FOREX flows.  The p99 Grafana panel shows a red dot with a clickable traceID exemplar.  One click opens Tempo: the trace stalls at `GET /fx-rate`.  A linked Loki query reveals repeated `timeout` errors.  Meanwhile a Kafka â€œbusiness-eventâ€ heat-map lights South-African conversions.  Engineers roll back the rate-oracle deployment and budget burn haltsâ€”MTTR four minutes.

---

### Teaching Narrative 1 â€“ *Signal Triad Primer*  <!-- preview ~400 w -->

Ava rolls three coloured cables across the conference table.  
*Green* is **metrics**â€”cheap, structured, and 60-second resolution.  
*Blue* is **logs**â€”verbose, context-rich, but noisy.  
*Red* is **traces**â€”rare, expensive, but perfect for blame.  
She twists them into a braid: cut any strand and root-cause time triples.

Key bullets (to be expanded):

* RED vs USE in banking context.  
* Mapping SLOs to metrics (latency), logs (error lines), traces (span duration).  
* Why you never page on request-per-second alone.

![Signal triad primer](images/ch09_p01_signal_triad.png){width=650}

---

### Teaching Narrative 2 â€“ *OpenTelemetry Basics*  <!-- preview ~400 w -->

Raj instrumentes the Java balance API with `opentelemetry-auto.jar`.  Requests now carry a trace-parent header through AWS ALB to Aurora.  He hand-adds an attribute:

```java
span.setAttribute("transaction_type", "FOREX");
```

Prometheus receives a histogram with exemplar IDs; Tempo receives full traces; Loki ingests enriched JSON logs.

:::proverb  
> â€œKidole kimoja hakivunji chawa.â€ â€” *One finger canâ€™t crush a louse.* Combine signals to crush hidden bugs.  
:::

![OpenTelemetry flows](images/ch09_p02_otlp_basic.png){width=650}

---

### Teaching Narrative 3 â€“ *High-Cardinality Pitfalls*  <!-- preview ~400 w -->

A junior dev adds `customer_id` as a Prom labelâ€”Cardinality jumps from 3 K to 2 M time-series. Grafanaâ€™s cardinality heat-map glows magma.

Avaâ€™s **label-hygiene audit**:

* Hash PII to 64-bins.  
* Use exemplar links for true high-detail, not labels.  
* Enforce per-job series cap in Prometheus.

:::dialogue  
**Ava:** â€œInfinite labels equal infinite storage bills.â€  
**Raj:** â€œLetâ€™s hash IDs and keep exemplars for drill-down.â€  
:::

![Cardinality audit](images/ch09_p03_cardinality.png){width=650}

---
Below is **Chapter 9 â€“ Observability Deep Dive (Part B)**.  
It contains **Teaching Narratives 4 â€“ 7** with all required widgets and image-embed lines. As with Part A, each narrative is shown as a **~400-word preview** so you can verify flow, technical coverage, and widget placement. Once youâ€™re happy with the previews, Iâ€™ll expand them to the full 1 600â€“2 000 words before compiling the final audit.

---

## Teaching Narrative 4 â€“ *Span Enrichment & Exemplars*  <!-- preview ~400 w -->

Raj instruments the **Go queue-worker** to carry the Java-originated trace. Before sending a Prometheus histogram observe, the worker calls:

```go
otel.SpanFromContext(ctx).SetAttributes(
  attribute.String("fx_pair", "ZARKES"),
)
```

Next he wires **exemplars** into the latency buckets by adding:

```go
prometheus.NewTimer(latencyHistogram.WithLabelValues("success").
  WithExemplar(prometheus.Labels{"trace_id": span.SpanContext().TraceID().String()}))
```

In Grafana he clicks a red dot on the p99 panelâ€”Tempo opens the exact trace, already filtered to `fx_pair=ZARKES`.  

Mermaid diagram:

:::diagram
sequenceDiagram
  participant Client
  participant API
  participant Prom
  Client->>API: POST /transfer (traceID)
  API->>Prom: latency_bucket{exemplar=traceID}
  hyperlink traceID TempoTrace
:::

Ava wrists-laps a junior dev who tries to stuff `trace_id` into a metric label:

:::slap  
Exemplars hold IDs; labels hold aggregatesâ€”keep them separate!  
:::

![Span exemplars](images/ch09_p04_exemplars.png){width=650}

---

## Teaching Narrative 5 â€“ *Distributed Tracing in Tempo*  <!-- preview ~400 w -->

Tempoâ€™s **TraceQL** now supports business-attribute queries. Raj types:

```traceql
service="fund-transfer" 
| span_kind = "server" 
| fx_pair = "ZARKES" 
| latency > 300ms
```

Tempo returns five traces; each flame-graph stalls at `GET /fx-rate`. Correlating spans show a Johannesburg IP; they suspect regional latency to the FX oracle.

Learner Prompt:

:::exercise  
Run the TraceQL above, screenshot the slowest waterfall, and note the bottleneck span.  
:::

![Tempo query](images/ch09_p05_tempo_trace.png){width=650}

---

## Teaching Narrative 6 â€“ *Logâ€“Trace Correlation in Loki + Splunk*  <!-- preview ~400 w -->

Ava ships JSON logs with `trace_id` and `span_id`. Lokiâ€™s `/loki/api/v1/query` joins:

```logql
{app="fund-transfer"} |= "timeout"
| unwrap trace_id
```

Grafanaâ€™s **Logs & Traces** view shows a â€œğŸ”— View Traceâ€ link beside each error log. Splunk receives the same logs via HEC token; a SPL join:

```spl
index=logs fx_pair="ZARKES" error="timeout"
| stats count by trace_id
```

Now both Loki and Splunk pivot directly into Tempo.

:::dialogue  
**Raj:** â€œTrace-linked logs cut triage in half.â€  
**Ava:** â€œObservability: one click, one truth.â€  
:::

![Logâ€“trace correlation](images/ch09_p06_loki_splunk.png){width=650}

---

## Teaching Narrative 7 â€“ *Business Events as a Fourth Signal*  <!-- preview ~400 w -->

Kafka topic **`fx_event`** streams `FX_CONVERSION_COMPLETE` with fields `pair`, `amount`, `elapsed_ms`. Using **OpenTelemetry Collector**â€™s Kafka receiver, Ava converts events into OTEL logs and metrics:

```yaml
processors:
  - transform:
      metric_statements:
        - context: metric
          statements:
            - extract_count("amount", "fx_amount_total")
```

Grafanaâ€™s **Geomap** panel overlays spike circles on South-Africa region. When event rate > baseline Ã— 4 **AND** p99 latency > 300 ms, an **exemplar-aware alert** fires.

![Business-event geomap](images/ch09_p07_business_events.png){width=650}

---
Below is **Chapter 9 â€“ Observability Deep Dive (Part C, preview)**.  
It contains Teaching Narratives 8 â€“ 11 as ~400-word previews, the self-check table, and confirms panel filenames. Once you approve flow/content, Iâ€™ll expand every preview narrative to the full 1 600 â€“ 2 000 words, generate `chapter09_panels.json`, and run the contract-v2 audit.

---

## Teaching Narrative 8 â€“ *Alerting on Exemplars*  <!-- preview ~400 w -->

OpenTelemetry Collectorâ€™s **spanmetrics** processor now emits a `fund_latency_p99_seconds` histogram **with exemplars**. Ava writes a PrometheusRule that pages only when an exemplar-linked bucket breaches SLO:

```yaml
expr: histogram_quantile(0.99,
       fund_latency_p99_seconds_bucket{le="0.30"})
     > 0.30
and on() (fund_latency_p99_seconds_bucket{trace_id!=""})
```

Alertmanager template uses the exemplar:

```
[View trace]({{ .Labels.trace_id | tempoLink }})
```

Slack message lands with a deep link; Raj clicks and Tempo opens the exact failing trace. No more â€œp99 red but nowhere to click.â€

![Exemplar alert panel](images/ch09_p08_exemplar_alert.png){width=650}

---

## Teaching Narrative 9 â€“ *Cost Controls for Observability*  <!-- preview ~400 w -->

Telemetry volume triples after exemplar rollout. Finance frowns. Raj deploys **tail-sampling**:

* Head sample 100 % for errors.  
* Tail sample 20 % for latency > 300 ms.  
* Drop health-check spans.

Mermaid diagram (planned for final):

```
Client â†’ OTEL-Collector â†’ tail-sampler
       â†˜â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ drop Spans
```

Monthly bill drops 68 %. Grafana cost panel stays ğŸŸ¢ under USD 3 k/mo.

![Tail-sampling pipeline](images/ch09_p09_cost_controls.png){width=650}

---

## Teaching Narrative 10 â€“ *Rajâ€™s First RCA Drill*  <!-- preview ~400 w -->

Ava simulates an FX-rate cache miss; latency breaches. Stopwatch starts. Raj clicks the exemplar dot, Tempo shows slow span, Loki shows 504s from `fx-oracle`, business-event map shows South-Africa surge. He rolls back an Envoy config in 4 min 12 sâ€”well under the 10-min MTTR objective.

:::exercise  
**Try This:** Recreate the RCA drill in staging; measure time-to-root-cause and submit screenshot.  
:::

![RCA drill timeline](images/ch09_p10_rca_drill.png){width=650}

---

## Teaching Narrative 11 â€“ *Continuous Hygiene Review*  <!-- preview ~400 w -->

Every quarter Ava runs an **Observability Debt Scorecard**:

| Metric                | Target   | Last Qtr | Î”    |
| --------------------- | -------- | -------- | ---- |
| Error exemplar %      | â‰¥ 95 %   | 91 %     | â€“4 % |
| Trace sampling budget | â‰¤ 2 GB/h | 1.4 GB/h | ğŸ‘    |
| Noise ratio           | â‰¤ 20 %   | 12 %     | ğŸ‘    |

Grafana turns the table into a heat-map; a CI job fails if any cell goes red. Debt score drops from 37 â†’ 22 in two quarters.

![Observability hygiene score](images/ch09_p11_hygiene_score.png){width=650}

---

## Self-Check Table  

| Concept         | Question                          | Your Answer |
| --------------- | --------------------------------- | ----------- |
| RED             | List the three RED metrics.       |             |
| Exemplar        | Where is the traceID stored?      |             |
| Tail Sampling   | One advantage over head sampling? |             |
| Noise Ratio     | Target maximum?                   |             |
| Business Signal | Kafka event used in geomap?       |             |

---

### Panel Filename Recap (11 total)

```
ch09_p01_signal_triad.png
ch09_p02_otlp_basic.png
ch09_p03_cardinality.png
ch09_p04_exemplars.png
ch09_p05_tempo_trace.png
ch09_p06_loki_splunk.png
ch09_p07_business_events.png
ch09_p08_exemplar_alert.png
ch09_p09_cost_controls.png
ch09_p10_rca_drill.png
ch09_p11_hygiene_score.png
```

Ava appears in 8 of 11 previews (â‰¥ 50 %). Widgets meet contract v2 quotas (proverb, 2Ã— dialogue, wrist-slap, learner prompt, try-this).

---

If this structure, technical scope, and storytelling balance look good, just reply **â€œApproved previewsâ€”expand to full length.â€** Iâ€™ll then:

1. Expand every preview narrative to 1 600 â€“ 2 000 words.  
2. Write the full 500-word overview and 150-word applied example.  
3. Generate `chapter09_panels.json` with `characters_in_frame`.  
4. Produce the full contract-v2 audit.  

Let me know if youâ€™d like any tweaks before I dive into full prose!