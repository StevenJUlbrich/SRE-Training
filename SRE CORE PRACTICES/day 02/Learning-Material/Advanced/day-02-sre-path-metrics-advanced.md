Yes. Letâ€™s go full beast mode. ğŸ‹ï¸â€â™‚ï¸

This is **Day 2 â€“ Advanced Metrics Tier**.  
This is **no longer about watching dashboards**â€”this is about **owning what goes on them**.

This is Marisol in her final form: sharp marker, IDE open, Grafana zoomed, and an app instrumented to expose the metrics *she* defined, not ones she inherited from some chaos engineer in 2017.

---
# ğŸ’¡ Day 2 â€“ Advanced Metrics:  
*â€œCustom Metrics, SLIs, and Building Dashboards That Explain Productionâ€*  
ğŸ™ Hosted by Marisol Vieira â€“ Data architect of your uptime, destroyer of vanity panels

---

## ğŸ¯ Goal

Equip engineers to:
- Define and expose meaningful, domain-specific metrics from services
- Use metrics to power SLIs and reliability goals
- Architect dashboards as **narrative tools**, not chart graveyards
- Scale Prometheus-aware systems (handling cardinality, federation, long-term storage)
- Own observability from code to visual to action

This isnâ€™t â€œmake a dashboard.â€ This is â€œdefine how your service tells its story.â€

---

## ğŸ§  Who This Is For

Youâ€™ve:
- Written real PromQL
- Built dashboards for teams or systems
- Lived through a broken alert and thought, *â€œwe should measure that differentlyâ€*
- Started asking, *â€œhow should this service *prove* itâ€™s healthy?â€*

Welcome. Youâ€™re ready for Advanced.

---

## ğŸ§ª Writing Custom Metrics in Code

### Whatâ€™s a custom metric?
Metrics *you* define in codeâ€”tailored to your systemâ€™s behavior.

Example:
```python
# Python (prometheus_client)
from prometheus_client import Counter

checkout_failures = Counter(
    'checkout_failures_total',
    'Number of failed checkouts',
    ['reason', 'region']
)

checkout_failures.labels(reason='timeout', region='us-east-1').inc()
```

> ğŸ”¥ This is observability ownership. Youâ€™re no longer reacting to system metrics. Youâ€™re building the signals that explain the user experience.

### Metric Type Decision Guide

| Use Case                     | Metric Type  |
|------------------------------|--------------|
| Count of events              | Counter      |
| Current value (e.g. queue)   | Gauge        |
| Distribution over time       | Histogram    |
| Percentiles needed           | Histogram*   |

> â— *Avoid **summary** unless you know exactly why. Histograms + PromQL are more flexible and recommended for most use cases.*

---

## ğŸ“ SLIs from Metrics

**SLI = Service Level Indicator**  
A precise, quantitative measure of system behavior that affects users.

Examples:
- âœ… Uptime: availability of `200` responses
- â± Latency: % of requests under 300ms
- ğŸ›‘ Error Rate: fraction of `5xx` responses
- ğŸš« Saturation: queue length or CPU above threshold

### How to Define One (Example: Login Latency)

1. Metric: `login_duration_seconds_bucket` (a Prometheus histogram)
2. Goal: 95% of logins under 400ms
3. Query:
```promql
histogram_quantile(0.95, sum(rate(login_duration_seconds_bucket[5m])) by (le))
```
4. Compare against threshold. Alert if it breaches for 5 mins.

### Mapping Metric to SLI to Alert

- **Metric**: `http_requests_total`
- **SLI**: % of requests returning 2xx/3xx
- **SLO**: 99.9% over 30 days
- **Alert**: If error rate > 0.1% for 5m, trigger page

---

## ğŸ“‰ Scaling Prometheus

Youâ€™re beyond just dashboards. Now youâ€™re planning observability systems.

### ğŸ’¾ Federation

- Break up scrape workloads by region/env
- Useful for multi-team, multi-tenancy setups

### ğŸ—ƒ Long-Term Storage (Thanos / Cortex)

- Store metrics for months/years
- Use cases:
  - SLA reporting
  - Historical regression analysis
  - Long tail reliability tracking

### âš  AlertManager Routing Strategy

- Group alerts by service
- Use routing trees by severity, team, on-call
- Add *playbooks* to alert messages!

---

## ğŸ¨ Dashboard as Narrative

> â€œA dashboard is an argument for or against system health.â€  
> â€” Marisol, after deleting 12 donut charts from staging

### ğŸ§° Structure for Operational Dashboards

| Section | Metrics (SLI-aligned) |
|---------|-----------------------|
| Top     | Uptime %, success rate, error budget burn |
| Middle  | p95/p99 latency, retry rate, queue length  |
| Bottom  | Resource metrics, alerts summary, deploy markers |

### Dashboard Patterns to Use

- **Heatmaps** for latency distributions
- **Bar charts** for comparisons (e.g., top N slow endpoints)
- **Single-stat** for high-level KPIs
- **Graph + Alert annotation** combo for incident reviews

---

## ğŸ§ª Advanced Exercises

### 1. Create a Custom Metric
- Use any language w/ `prometheus_client`
- Implement:
```text
orders_queued_total{priority="high"}
```
- Simulate updates
- Expose on `/metrics` (the default Prometheus endpoint), validate in browser or curl

> âš ï¸ **Tip:** Be mindful of label cardinality when designing custom metrics. Too many unique label values can overload your monitoring system.

---

### 2. Define an SLI for a Critical Path
- Use your appâ€™s real data or mock metric
- Pick an SLI (latency, error, etc.)
- Write the query
- Define SLO target (e.g., 99.95%)
- Draft the alert rule

---

### 3. Build a Dashboard That Tells a Story
- Goal: Show â€œIs `checkout-service` working right now?â€
- Must include:
  - Latency distribution
  - Error rate (non-2xx)
  - Throughput (requests/sec)
  - Uptime or health check indicator
- Bonus: Add deployment markers

---

## âœ… What You Should Know Now

You now:
- Understand how to define and expose new metrics from your service
- Can turn raw data into SLIs and meaningful alerts
- Know how to scale observability infrastructure with Prometheus
- Can build dashboards that communicate operational health clearly and concisely

---

## ğŸ§± Youâ€™ve Reached the Top Brick

Marisolâ€™s parting words:
> â€œMetrics arenâ€™t data. Metrics are **proof**. Proof that your service works. Or doesnâ€™t.â€

Next up? Apply this to an incident, a postmortem, or SLO rollout.

Or, you know, go delete a panel titled â€œPanel Title.â€ Youâ€™ve earned it.


