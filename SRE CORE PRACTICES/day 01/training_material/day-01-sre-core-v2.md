# DayÂ 1 â€“ Foundations of Observability  
*(SRE Core Training Curriculum)*Â îˆ€citeîˆ‚turn0file0îˆ  

---

## 1Â Â Character Introduction *(Narrator)*  

> **MeetÂ Hector Alvarez â€“ â€œElÂ Viejoâ€ of SiteÂ Reliability**  
> Veteran SRE, Mexico City native, twentyâ€‘plus years of uptime scars. Sardonic grin, coffeeâ€‘stained RHEL baseball cap, and an allergy to â€œpretty dashboards with no soul.â€  

**Memorable quote**

> â€œMonitoring tells you your pulse; observability tells you why your heartâ€™s racing.â€  

---

## 2Â Â Realâ€‘World Incident Hook *(Hectorâ€™s Voice)*  

â€œLast summer our payments API *looked* greenâ€”CPUÂ 25Â %, error rate <Â 0.1Â %. Yet customers from SÃ£oÂ Paulo to Stockholm were hammering Twitter about declined cards.  
I opened Splunk on my RHEL9 jumpâ€‘box, tailed structured logs, and *boom*â€”a single downstream fraudâ€‘check service was timing out for nonâ€‘US BINs. Metrics were too coarse to see the spike; traces werenâ€™t stitched in. Fiftyâ€‘seven minutes of reputation damage weâ€™ll never get back. If weâ€™d wired *real* observabilityâ€”metrics tied to traces tied to logsâ€”weâ€™d have paged the right team in five.â€  

*Lesson*: Healthy nodes â‰  happy users. Only correlated signals reveal user pain early.

---

## 3Â Â Learning Objectives *(Narrator)*  

| Level | You will be able toâ€¦ |
|-------|----------------------|
| ğŸ” **Beginner** | Distinguish **monitoring vs. observability**, list the **3Â Pillars**. |
| ğŸ§© **Intermediate** | Apply the **ObserveÂ â†’Â TestÂ â†’Â EvaluateÂ â†’Â Act** (OTEA) loop; map signals to user journeys. |
| ğŸ’¡ **Advanced / SRE** | Sketch a highâ€‘level **observability architecture** and position your org on the **maturity model**. |

---

## 4Â Â Core Concepts *(Mixed NarratorÂ +Â Hector)*  

### 4.1Â Observability vs. Monitoring  
Monitoring = *knownâ€‘unknowns* (â€œalert when CPUÂ >Â 80Â %â€).  
Observability = tooling + culture to answer *unknownâ€‘unknowns* without code change.  

### 4.2Â The Three Pillars  

```mermaid
graph TD
  A[Metrics] --> G[GoldenÂ Signals]
  B[Logs] --> G
  C[Traces] --> G
  G --> D[UserÂ Experience]
```

### 4.3Â Golden Signals  
LatencyÂ â±Â Â â€¢Â Â TrafficÂ ğŸ“ˆÂ Â â€¢Â Â ErrorsÂ âŒÂ Â â€¢Â Â SaturationÂ ğŸš¦  

### 4.4Â OTEA Framework  

```mermaid
sequenceDiagram
  autonumber
  participant O as Observe<br>(collect signals)
  participant T as Test<br>(hypothesize)
  participant E as Evaluate<br>(correlate data)
  participant A as Act<br>(mitigate)
  O-->>T: Signal anomaly
  T-->>E: Formulate tests
  E-->>A: Pinpoint fault
  A-->>O: Verify remediation
```

### 4.5Â Maturity Model (0â†’4)  
0Â =Â Ping checks â†’ 1Â =Â Basic host metrics â†’ 2Â =Â Service metrics & logs â†’ 3Â =Â Distributed tracing â†’ 4Â =Â Autoâ€‘instrumented, businessâ€‘level SLIs.

---

## 5Â Â Python Implementation *(Narrator)*  

### 5.1Â Baseline Flask App with Metrics & Structured Logging  

```python
# app.py â€“ run on RHEL9
from flask import Flask, jsonify
from prometheus_client import Counter, Histogram, generate_latest
import logging, time, random, os

app = Flask(__name__)

REQUESTS = Counter("http_requests_total", "Total HTTP requests", ["endpoint"])
LATENCY  = Histogram("http_request_latency_seconds", "Latency", ["endpoint"])

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
)

@app.route("/healthz")
def health():
    return "ok", 200

@app.route("/pay")
@LATENCY.labels("/pay").time()
def pay():
    REQUESTS.labels("/pay").inc()
    if random.random() < 0.05:
        logging.error("card_declined", extra={"txn_id": os.urandom(4).hex()})
        return jsonify(status="declined"), 502
    return jsonify(status="approved")

@app.route("/metrics")
def metrics():
    return generate_latest(), 200, {"Content-Type": "text/plain; charset=utf-8"}

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

*Run*: `pip install flask prometheus-client && python app.py`  
*Ship logs*: `python app.py | splunk forwarder â€¦`  

### 5.2Â Bonus â€“ Correlating Metrics, Logs & Traces  
Add OpenTelemetry instrumentation (`opentelemetry-instrument flask`) and send spans to Jaeger. Use traceâ€‘ID field to join Splunk logs and Prometheus metrics.

---

## 6Â Â Handsâ€‘On Exercise *(Hectorâ€™s Voice)*  

**Scenario** â€“ Three screenshots (share in class):  

1. *Prometheus* shows `http_request_latency_seconds` p95 = 200Â ms (green).  
2. *Flask logs* in Splunk reveal bursts of `card_declined`.  
3. *Jaeger trace* shows 50Â % of `/pay` spans missing child span `fraud_check`.  

**Task** â€“ Which pillar is lying?Â Why?  

**Success Criteria**  

- Identify **metrics** as misleading (latency OK but business errors high).  
- Explain correlation path: Logs show errors â†’ traces show missing calls â†’ root cause = downstream fraudâ€‘service outage.  

**Solution Path**  

```mermaid
graph TD
  M(Metrics<br>green) -->|misleading| X[Analysis]
  L(Logs<br>error bursts) --> X
  T(Traces<br>broken span) --> X
  X --> R[Root&nbsp;Cause<br>fraud_service 5xx]
```

*(Students document steps; compare to Hectorâ€™s walkâ€‘through at session end.)*

---

## 7Â Â Dashboard Fundamentals *(Narrator)*  

| Panel | What to display | Why it matters |
|-------|-----------------|----------------|
| **1Â â€“ Latency & Traffic** | p95 latency line + RPS bar | Instant view of load vs. speed |
| **2Â â€“ Error Rate** | `http_errors_totalÂ /Â http_requests_total` | Surface userâ€‘visible failure |
| **3Â â€“ Saturation** | CPU %, Mem %, queue depth | Capacity forecasting & throttling |

Tie panels with shared **traceâ€‘ID** linkâ€‘outs and Splunk deepâ€‘links. Keep *one* color scale per metric to avoid visual noise.

---

## 8Â Â Common Pitfalls *(Hectorâ€™s Voice)*  

1. **Graphâ€‘Spam** â€“ â€œOne dashboard per developer.â€ âœ‚ï¸Â Trim to GoldenÂ Signals.  
2. **Unlabeled Metrics** â€“ No `txn_id` or `customer_region` label? Enjoy guessing at 3Â AM.  
3. **SilentÂ Sampling** â€“ Tracing 0.1Â % of traffic hides 99Â % of outliers.  
4. **Ignoring Bash Oneâ€‘Liners** â€“ `curl -w "%{time_total}"` is still the fastest SLI smokeâ€‘test.  

---

## 9Â Â Hectorâ€™s Commandments *(Hectorâ€™s Voice)*  

1. **â€œLogs without context are rumors.â€** Log *what* happened *and* *why*.  
2. **â€œEvery alert must map to a user journey.â€** Otherwise delete it.  
3. **â€œIf you canâ€™t replay it in Splunk on RHEL9, you didnâ€™t measure it.â€**  

---

## 10Â Â Key Takeaways & Handoff *(Narrator)*  

- Observability â‰  stacks of metricsâ€”itâ€™s *correlated insight* that shortâ€‘circuits downtime.  
- The **OTEA loop** gives a repeatable method to debug the unknownâ€‘unknowns.  
- Start with a **3â€‘panel Golden Signal dashboard**; evolve as maturity grows.  

*Tomorrow (DayÂ 2)* youâ€™ll meet **Aanya Patel**, the IncidentÂ Commander from Bangalore, and dive into **Incident Response Fundamentals**â€”alert design, onâ€‘call etiquette, and runâ€‘book automation. Donâ€™t forget Hectorâ€™s parting words:  

> â€œDataâ€™s cheap; insightâ€™s pricelessâ€”see you at 0600.â€  

---