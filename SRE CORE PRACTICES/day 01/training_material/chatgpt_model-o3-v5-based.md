# DayÂ 1 Training Module â€” **Foundations of Observability** 
---

## 1. Introduction: Observability Foundations  

### Welcome  
> *â€œIf you canâ€™t **see** the system clearly, you canâ€™t **save** it quickly.â€*  

Today we begin the journey from traditional **monitoring** to holistic **observability**. You already watch dashboards in Geneos, Splunk, Dynatrace, and Datadog; now weâ€™ll learn to **connect the dots** so numbers, logs, and traces tell one coherent story.

### The Oâ€‘Tâ€‘Eâ€‘A Loop  
| Phase | What you do | Typical Tooling |
|-------|-------------|-----------------|
| **O**bserve | Collect signals (metricsÂ /Â logsÂ /Â traces) | Prometheus, Geneos agents |
| **T**estÂ (Question) | Form a hypothesis | Kibana, Grafana Explore |
| **E**valuate | Correlate & confirm | Splunk SPL, Datadog Notebooks |
| **A**ct | Remediate / automate | CI/CD, Runbooks, ArgoCD |

### MonitoringÂ â‰ Â Observability  
Monitoring asks **â€œIs it up?â€**; observability asks **â€œ*Why* is it misbehaving?â€** Both are essential: monitoring raises the flag, observability guides the fix.

```mermaid
graph LR
    M["Monitoring: "Is it healthy?""] -.->|alerts| O["Observability: "Why is it unhealthy?""]
    O --> M
```

### The Three Pillars at a Glance  
```mermaid
graph TD
    Metrics["<b>Metrics</b><br>Numbers &amp; rates"] --> O
    Logs["<b>Logs</b><br>Events &amp; context"] --> O
    Traces["<b>Traces</b><br>Request journey"] --> O
    O[Observability]
```

### From Monitoring to Mature Observability  
```mermaid
graph TD
    A[Adâ€‘hoc Monitoring] --> B[Dashboards &amp; Alerts]
    B --> C[Correlated Pillars]
    C --> D[SLOs #38; Error Budgets]
    D --> E[Selfâ€‘Healing Automations]
```

**Learning Objectives**  
- **BeginnerÂ ğŸ”**â€‚Describe each pillar and when to use it.  
- **IntermediateÂ ğŸ§©**â€‚Correlate pillars to validate hypotheses.  
- **Advanced/SREÂ ğŸ’¡**â€‚Design scalable pipelines and SLOâ€‘driven alerts.

*(YouTube intro placeholder â†’ **{{VIDEO_LINK_INTRO}}**)*  

---

## 2. MetricsÂ â€”Â The Quantitative View  

### ğŸ”Â Beginner  
**Analogy:** A car dashboard: speedometer (gauge), odometer (counter), 0â€‘60 timer (histogram).  

| Metric Type | Definition | Real Example in Geneos |
|-------------|------------|------------------------|
| **Counter** | Monotonic, only up | `payments_total` |
| **Gauge** | Up & down | JVM heap used |
| **Histogram** | Bucketed distribution | API latency buckets |

```mermaid
graph LR
    App[(App)] -->|Exporters| Prometheus{{Prometheus}}
    Prometheus --> Grafana[(Grafana Panels)]
```

### ğŸ§©Â Intermediate  
*RED & USE methods*  
- **RED:** *Rate*, *Errors*, *Duration* â€” ideal for **userâ€‘facing** services.  
- **USE:** *Utilization*, *Saturation*, *Errors* â€” ideal for **infrastructure**.  

**Naming & Cardinality Tips**  
`service:operation:latency_seconds_bucket{le="0.5"}` â€” keep labels lowâ€‘cardinality!

### ğŸ’¡Â Advanced/SRE  
- Alert **on burn rate**, not raw errors.  
- Shard Prometheus or use Cortex/Thanos for >10Â million timeâ€‘series.

#### Horror Story (#1 â€” Metrics Saved the Day)  
A silent drop in checkout success reached onlyÂ 0.5Â % errorâ€‘rate â€” below legacy Geneos alert. A **histogram SLO alert** fired in Prometheus, pointing to elevated p95 latency in `charge-card`. Quick rollback saved \$40Â k revenue in 12Â min.

**Interview Questions**  
1. When would you choose a **Summary** over a **Histogram**?  
2. Explain how youâ€™d alert on a 4â€‘hour errorâ€‘budget burn within 1Â hour.  

*(Metrics deepâ€‘dive video â†’ **{{VIDEO_LINK_METRICS}}**)*  

---

## 3. LogsÂ â€”Â The Narrative Thread  

### ğŸ”Â Beginner  
**Analogy:** Shipâ€™s logbookâ€”every event recorded in time order.

```mermaid
graph TD
    App[(App)] --> Fluentbit
    Fluentbit --> Splunk{{Splunk IDX}}
    Splunk --> Analyst[(Search &amp; Dashboards)]
```

**Structured vsÂ Unstructured**  
- JSON, keyâ€‘value pairs â†’ **searchable** and **aggregateable**.  
- Freeâ€‘text â†’ only good for grep & hope.

### ğŸ§©Â Intermediate  
- **Correlation IDs** tie log lines to traces.  
- **Context enrichment** (host, k8s namespace) accelerates triage.  
- **Sampling** highâ€‘volume noisy logs to 10Â % cuts cost 80Â % with minimal signal loss.

### ğŸ’¡Â Advanced/SRE  
- Build **dynamic parsing rules** (e.g., SplunkÂ TA) to adapt to new log schemas.  
- Hot/warm/cold storage tiers for compliance & cost.

#### Horror Story (#2 â€” Logs Saved the Day)  
A VSI batch job intermittently deleted invoices. Metrics looked normal. A single **WARN** line buried in 5Â GB logs showed `truncate table invoices`. Correlation ID led to misâ€‘scoped Flyway migration in staging config leaked into prod. Twoâ€‘line rollback script, issue resolved, auditors happy.

**Interview Questions**  
1. Why might you **sample** DEBUG logs but not ERROR logs?  
2. Show a SPL query joining Kubernetes labels with application fields.  

*(Logging essentials video â†’ **{{VIDEO_LINK_LOGS}}**)*  

---

## 4. TracesÂ â€”Â The Requestâ€™s Journey  

### ğŸ”Â Beginner  
**Analogy:** GPS route showing each waypoint (span) of your commute.

```mermaid
sequenceDiagram
    participant UI
    participant API
    participant Payment
    UI->>API: HTTP POST /pay
    API->>Payment: gRPC Charge
    Payment-->>API: 200 OK
    API-->>UI: 200 OK
```

- **Span** = single operation, **Trace** = tree of spans, **Context** travels via headers.

### ğŸ§©Â Intermediate  
- **Headâ€‘based sampling** (drop early) vs **tailâ€‘based** (decide after latency known).  
- Visualize critical path to chase the *slowest span*.

### ğŸ’¡Â Advanced/SRE  
- **Baggage vsÂ Traceâ€‘Context**: keep baggage â‰¤Â 8Â KB or pay the price.  
- Jaeger + OpenTelemetry collector scaling tips: use **kafka** pipeline for >50Â kÂ spans/s.

#### Horror Story (#3 â€” Traces Saved the Day)  
Checkout latency spiked only for AWSÂ euâ€‘westâ€‘1 customers. A trace heatâ€‘map highlighted a hidden network call from `fraudâ€‘svc` to an onâ€‘prem LDAP over VPN (400Â ms). Caching token locally fixed the issueâ€”frontâ€‘end latency fell from p95 2Â s â†’Â 300Â ms.

**Interview Questions**  
1. Compare **span attributes** vs **baggage**.  
2. How would you instrument a Kafka consumer without doubleâ€‘counting latency?  

*(Tracing walkthrough video â†’ **{{VIDEO_LINK_TRACES}}**)*  

---

## 5. Integrating the Three Pillars  

```mermaid
graph TD
    A[Metric Alert<br>checkout_p99 &gt; 750ms] --> B[Trace Search<br>recent slow IDs]
    B --> C[Log Drilldown<br>context of trace ID]
    C --> D[Root Cause<br>DB pool exhaustion]
```

**Correlation Patterns**  
1. **Start with metric alert** â†’ retrieve trace IDs with high latency.  
2. Use trace ID to **filter logs** for context.  
3. Confirm fix by watching metric drop and trace durations shrink.

**RefÂ Architecture (Kubernetes)**  
```mermaid
graph LR
    Pod1 --> OtelAgent
    Pod2 --> OtelAgent
    OtelAgent --> Prometheus
    OtelAgent --> Loki[Loki Logs]
    OtelAgent --> Tempo[Tempo Traces]
    Prometheus --> Grafana
    Loki --> Grafana
    Tempo --> Grafana
```

#### Horror Story (#4 â€” Integrated Pillars Win)  
A Dynatrace alert flagged CPU on `quoteâ€‘svc`. Traces showed normal latency, but linked logs revealed bursty GC. Heap histogram metric confirmed leak. Hotfix rolled out; incident closed before pager hit levelâ€‘2.

**Interview Questions**  
1. Describe an **exemplars** workflowâ€”metrics label pointing to trace.  
2. How would you migrate from Geneos monosilos to this architecture gradually?  

*(Integration demo video â†’ **{{VIDEO_LINK_INTEGRATION}}**)*  

---

## 6. Knowledge Check & Wrapâ€‘Up  

### Quick Quiz (selfâ€‘graded)  
1. **ğŸ”**â€‚Name the three metric types and give one example each.  
2. **ğŸ§©**â€‚Which methodâ€”RED or USEâ€”fits **database CPU saturation**? Why?  
3. **ğŸ’¡**â€‚How can tailâ€‘based sampling improve *outlier* detection?  
4. **ğŸ”**â€‚Structured log advantage over plain text?  
5. **ğŸ§©**â€‚What header carries trace context in W3C spec?  
6. **ğŸ’¡**â€‚Explain *burnâ€‘rate* alerting in one sentence.  

*(Answer key in the facilitatorâ€™s guide.)*

### Todayâ€™s Takeaways  
- Observability **augments** monitoringâ€”keep both.  
- Metrics tell **what**, logs tell **when/where**, traces tell **why/how**.  
- Correlating pillars shortens MTTR dramatically.  
- Start capturing **standard IDs** (trace_id) now; it pays off later.  

### Coming Up  
| Day | Focus |
|-----|-------|
| **DayÂ 2** | SLOs & Error Budgets â€” metrics into promises |
| **DayÂ 3** | Instrumentation Deepâ€‘Dive â€” OpenTelemetry handsâ€‘on |

### Recommended Resources  
- *Observability Engineering* (Oâ€™Reilly) chaptersÂ 1â€‘3  
- CNCF OpenTelemetry Workshop (YouTube)  
- Honeycombâ€™s *Guides to Highâ€‘Cardinality* blog series  

---

*End of DayÂ 1 module â€” see you tomorrow!*  

---

