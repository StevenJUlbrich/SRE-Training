# Chapter 2 â€“ â€œThe Problem Isnâ€™t Always the Problemâ€

______________________________________________________________________

### Chapter Overview

A banking outage never begins with flames on a dashboard. It starts in the quiet places â€” a teller noticing failed wire-transfer receipts, a queue lengthening in the background, a lone terminal log winking red and then rolling off the screen. In this chapter Hector Alvarez drags the learner cast through a failure born not of hardware, but of **invisibility**: a single configuration toggle that silenced every trace the system could have shouted. When observability disappears, blame becomes the loudest tool in the room.

Across nine cinematic panels (delivered here in two parts), you will watch Wanjiru, Katherine, and Juana confront a mystery crash that looks serene from the outside. You will follow their mis-steps, inspect raw logs with missing trace context, and witness Hectorâ€™s uncompromising debrief on why telemetry is an engineering featureâ€”not an afterthought. By the end, you should know how a missing `trace_id` can fracture incident response, and how a single unchecked box (`enableTracing=true`) can buy an outage while nobodyâ€™s looking.

Part A covers Panels 1â€“4, guiding you from first symptom through flashback to the silent configuration error. Each panel adheres to the contract cadence: **Learning Objective â–¸ Takeaway â–¸ Applied Example â–¸ Teaching Narrative â–¸ Image Embed (+ widget)**, embedding one widget per teaching sequence and ensuring that Hectorâ€™s gravel-dry wisdom lands exactly where the outline demands.

______________________________________________________________________

## Panel 1 â€“ **The Mystery Crash**

### ğŸ¯ Learning Objective

Realize that user-reported pain can surface long before any metric twitches. Incident response must start with the user story, not the CPU graph.

### âœ… Takeaway

â€œIf the customer hurts and the dashboard doesnâ€™t, your dashboards are blind.â€

### ğŸš¦ Applied Example

```bash
# Customer-service agent escalates ticket ID 5219
curl -X POST https://api.bank.example/v1/wire \
     -H "x-customer-id: 34800917" \
     -d '{"amount": 1200, "currency": "USD"}'
> HTTP/1.1 500 Internal Server Error
> trace-id:  âŒ **<header missing>**
```

### Teaching Narrative

Itâ€™s 08 : 17 AM when the first teller in the Nairobi branch files an urgent Jira. Wire transfers stall at step two; customer confirmation receipts never print. Katherine Gitonga, half a croissant in one hand and a Geneos dashboard on the other, zooms straight into *CPU Utilization*. The graph is flatter than a desert horizon.

> Katherine (muttering): â€œCPUâ€™s fine. Memoryâ€™s fine. Must be a glitch in the queue.â€

Across the aisle Wanjiru Maina pulls up **Payment-Service Error Rate**. Green, steady. No alarms. She shrugs, puzzled. A Slack channel called `#wire-ops` flickers to life with angry emojis from Customer-Care.

Your first instinct might be to scan every metric panel for a tell-tale red spike. Hector would call that *dashboard astrology*. In banking, a single user-visible failure outranks a thousand â€œhealthyâ€ graphs. The system is whispering; youâ€™re just reading the wrong lips.

:::try this
Open your favourite banking sandbox and disable a single downstream dependency (e.g., the ledger update call).

1. Observe the **user-facing** error.
2. Look at your standard CPU/Memory metrics.
3. Note how little they complain.\
   **Question:** What *should* you instrument so the outage shows up instantly?
   :::

### Image Embed

![Alt text](images/panel1_mystery_crash.png){width=640}

:::hector quote
**Hector says:** â€œGreen dashboards during a user scream-fest? Thatâ€™s the system pleading the Fifth.â€
:::

______________________________________________________________________

## Panel 2 â€“ **Dashboard Deceit, Part II**

### ğŸ¯ Learning Objective

Understand that system-level resource graphs (CPU, memory) can falsely reassure responders when business transactions fail.

### âœ… Takeaway

Resource steadiness â‰  service correctness. Metrics must align to *business outcomes*.

### ğŸš¦ Applied Example

```json
{
  "payment_service.cpu": { "avg": 34.2 },
  "payment_service.mem": { "rss_mb": 512 },
  "payment_service.error_rate": 0.0,
  "ledger_service.queue_depth": 2     // <â€” hidden below alert threshold
}
```

### Teaching Narrative

Geneos glows tranquil. Katherine zooms deeper, toggling one-minute resolution. Still nothing. Wanjiru adds a **90-percentile latency** panel. The line wiggles inside tolerance. They exchange a glance â€” â€œmaybe the tellerâ€™s workstation is flaky?â€

Juana Torres appears, silent as midnight maintenance. She tilts her laptop so the others see a real-time feed of failed HTTP 500s from customer endpoints. Thirty-seven in two minutes.

> Wanjiru: â€œThatâ€™s impossible. Error rate panel shows zero.â€\
> Juana (raising an eyebrow): â€œDashboard must be wired to the wrong metric.â€

Hector will later call this **Metric-Mirror Syndrome**: when teams chart a symptom unrelated to the customer journey and declare victory. The bank doesnâ€™t care about CPU; it cares about money moving.

### Image Embed

![Alt text](images/panel2_dashboard_deceit.png){width=640}

:::incident flashback
Last quarter, a European branch missed â‚¬4 million in FX trades because their â€œlatencyâ€ chart measured a mock endpoint, not the real one. The post-mortem footer read: *SLI definition: TBD*.
:::

______________________________________________________________________

## Panel 3 â€“ **The Missing Trace**

### ğŸ¯ Learning Objective

Expose how missing trace context turns error logs into dead ends.

### âœ… Takeaway

A log without a `trace_id` is a postcard with no return address.

### ğŸš¦ Applied Example

```
2025-04-30T08:19:12Z ERROR wire-transfer-svc[2388]: 
  message="NullPointerException"
  method="/wire"
  status=500
  trace_id=            â¬…ï¸  (empty)
```

### Teaching Narrative

Juanaâ€™s fingers dance across the keys:

```bash
grep -i "NullPointerException" /var/log/wire-transfer.log | tail -n 3
```

Every line identicalâ€”same method, same stack trace, **no `trace_id` field**. She tries `kubectl exec` into another pod; same emptiness. The request path is a cul-de-sac.

> Juana (dry): â€œClassic. Someone clipped trace injection again.â€\
> Katherine: â€œWe had spans last sprint. Whereâ€™d they go?â€\
> Wanjiru: â€œCould config haveâ€¦?â€

Your team just discovered an unobservable failure. Without span context, you cannot stitch together the ledger call, auth service hop, or database rollback that actually blew up. You are chasing ghosts with a flashlight whose batteries died a release ago.

:::reflection
Think back to your last outage. Did every error log include a correlation or trace ID? If not, *how long* did you spend guessing which downstream call exploded?
:::

### Image Embed

![Alt text](images/panel3_missing_trace.png){width=640}

:::hector quote
**Hector says:** â€œLogs without context are gossip. Add IDs or keep guessing who started the fire.â€
:::

______________________________________________________________________

## Panel 4 â€“ **What They Missed**

### ğŸ¯ Learning Objective

Show that configuration drift can silently disable observability features, turning a mild refactor into a critical blind spot.

### âœ… Takeaway

Observability is a **feature flag**; treat it with the same rigor as functionality.

### ğŸš¦ Applied Example (Git Diff)

```diff
- enableTracing = true
+ enableTracing = false   # temporary perf test
```

`commit 4a9e12d  (message: "minor perf fix")`

### Teaching Narrative

Juana digs into the previous nightâ€™s deployment diff. A junior dev disabled tracing for a load-test, promised to revert, and merged anyway.

> Flashback: A neon-lit code review room. The dev types â€œJust disabling tracing to squeeze perf ğŸ˜Šâ€. The PR merges with two quick ğŸ‘.

Performance test passed. Tracing died. Production lost its voice.

Katherine exhales sharply. â€œWe chased metrics for twenty minutes while the real clue was sitting in Git history.â€

Hector steps through the doorway like a human post-mortem.

> Hector: â€œObservability isnâ€™t magic. Itâ€™s preparation. And you didnâ€™t prepare.â€

He slams a laminated sequence diagram onto a tableâ€”arrows labelled with missing spans, empty IDs where context should be. The team gathers, cheeks warming with the particular shame of hindsight.

:::debug pattern
**Pattern Name:** Missing Span Syndrome\
**Description:** Logs and metrics show failure, but lack request-path context because trace injection was disabled.\
**Example Fix:** Enforce middleware that adds trace headers at ingress, emits span IDs at every hop, and blocks deployment when `enableTracing=false`.
:::

### Image Embed

![Alt text](images/panel4_config_regression.png){width=640}

:::hector quote
**Hector says:** â€œTelemetry you *turn off* will come back for payment â€” with compound interest.â€
:::

______________________________________________________________________

## Panel 5 â€“ **The Blame Game Begins**

### ğŸ¯ Learning Objective

Recognize how the absence of shared telemetry shifts an incident from *root-cause analysis* to *political dodge-ball*.

### âœ… Takeaway

â€œWhen nobody can *see* the bug, everybody *is* the bug.â€

### ğŸš¦ Applied Example â€” Slack Scroll

```text
08 : 24 #wire-ops
Ops-Lead â–¶ï¸  â€œDB timeoutsâ€”infra latency again?â€
Dev-Lead â–¶ï¸  â€œYour nodes are starving the JVM.â€
Net-Eng  â–¶ï¸  â€œTraceroute clean. Have you re-checked the app toggle?â€
PM        â–¶ï¸  â€œCustomers still angry. Who owns this?â€
```

### Teaching Narrative

The war-room chat explodes. Ops reposts a â€œnetwork latencyâ€ chart that looks normal. Devs paste a screenshot of pod restarts that also looks normal. Infra counters with a green graph from the load-balancer.\
Wanjiru whispers, â€œIs itâ€¦ possible weâ€™re all staring at the wrong thing?â€ Katherine doesnâ€™t answerâ€”heâ€™s busy drafting a blame matrix for the postmortem.

Outside the thread, Jamal the Customer-Experience Director sighs: *â€œUsers donâ€™t care which team â€˜wins.â€™ They just want to move money.â€* The system is down; careers are up for auction.

:::reflection
In your last incident, how many distinct teams posted *completely different* dashboards to prove innocence? Count them. What single source-of-truth could have stopped the brawl?
:::

### Image Embed

![Alt text](images/panel5_blame_game.png){width=640}

:::hector quote
**Hector says:** â€œFinger-pointing is the smoke. Missing telemetry is the fire.â€
:::

______________________________________________________________________

## Panel 6 â€“ **Hector Steps In**

### ğŸ¯ Learning Objective

Understand that observability must be *gated*â€”you cannot ship code if it canâ€™t confess.

### âœ… Takeaway

â€œInstrumentation is part of the feature. Shipping without it is shipping broken.â€

### ğŸš¦ Applied Example â€” Post-Merge Gate Stub

```yaml
tracingCheck:
  run: ./ci/trace-lint.sh
  mustPass: true
```

### Teaching Narrative

Hector enters, drops his mug, and kills the conference-room lights. A single projector beam shows an old outage timeline:

> **2017-10-03, 02 : 11 UTC** â€” European SEPA wires lost â‚¬23 M because trace headers were stripped by an NGINX upgrade.\
> **Impact:** 14-hour reconciliation drill, 4 regulators, one 8-figure fine.

He turns to the group. â€œYouâ€™re following the same scriptâ€”except this time, the auditors are *already on the call*.â€\
Juana gulps; Katherine closes his blame spreadsheet. Hector flips to the next slide: a red CI step named **`telemetry-gate`**. It fails commits that disable tracing.

> Hector: â€œYou built a house without smoke detectors. Then argued about who smelled smoke first.â€\
> Wanjiru (quietly): â€œLetâ€™s install detectors before we rebuild the kitchen.â€

:::incident flashback
During a 2021 ACH backlog, an intern hot-patched a feature flag that muted all trace exports. Two hours later, 19 000 transfers vanished into an SQS queue black hole. The fix? Re-enable tracing and *rerun every transfer by hand* at midnight.
:::

### Image Embed

![Alt text](images/panel6_hector_steps_in.png){width=640}

:::hector quote
**Hector says:** â€œLogs tell stories. Traces draw the crime-scene chalk. Ship bothâ€”or enjoy the unsolved mystery.â€
:::

______________________________________________________________________

## Panel 7 â€“ **The Corrected View**

### ğŸ¯ Learning Objective

Demonstrate how a fully instrumented trace graph reveals the *real* failing hop within seconds.

### âœ… Takeaway

A single end-to-end trace short-circuits hours of speculation.

### ğŸš¦ Applied Example â€” Before vs After Trace IDs

```diff
- trace_id =
+ trace_id = 8af5-c2b7-f1d0
+ parent_span_id = c11e-9ab3
```

### Teaching Narrative

Juana toggles the flag, redeploys, and reloads Grafana-Tempo. A vivid service map blossoms: `web` â” `auth` â” **`ledger-svc` (1 290 ms, red)** â” `db`.\
Hector overlays the pre-fix viewâ€”an empty white voidâ€”with the new colorful DAG.

> Katherine: â€œThat ledger hop is *7Ã—* slower than baseline!â€\
> Wanjiru: â€œAnd every failed wire dies *right there*.â€\
> Juana: â€œTelemetry wasnâ€™t the cost. Ignorance was.â€

:::diagram

```mermaid
sequenceDiagram
  autonumber
  actor User
  participant Web
  participant Auth
  participant Ledger
  participant DB
  User->>Web: POST /wire
  Web->>Auth: /authorize
  Auth-->>Web: 200
  Web->>Ledger: /commit
  Ledger-->>DB: INSERT wire_txn
  DB-->>Ledger: 201
  Ledger-->>Web: 500 (latency 1290 ms)
  Web-->>User: 502 Bad Gateway
```

:::

:::debug pattern
**Pattern Name:** Trace Resurrection\
**Description:** Outages masked by missing spans; once restored, a single pathological hop becomes obvious.\
**Example Fix:** Gate merges on active span sampling, display p95 latency color-coded on the trace graph, and link errors to span IDs in logs.
:::

### Image Embed

![Alt text](images/panel7_corrected_view.png){width=640}

:::hector quote
**Hector says:** â€œSpans are receipts. Keep them, or refund the incident time.â€
:::

______________________________________________________________________

## Panel 8 â€“ **Team Realization**

### ğŸ¯ Learning Objective

Move learners from passive spectators to *owners* of telemetry quality.

### âœ… Takeaway

Instrument once; verify always; blame never.

### ğŸš¦ Applied Example â€” Guard Rail PR

```diff
+ if [[ "$TRACE_FLAG" != "true" ]]; then
+   echo "âŒ Tracing disabled. Rejecting build."
+   exit 1
+ fi
```

### Teaching Narrative

Katherine commits a guard-rail script; Wanjiru approves within seconds. CI passes. A fresh deploy rolls out; Grafana shows error rate collapsing from **12 %** to **< 0.4 %**.\
Jamal posts in `#wire-ops`: *â€œTransfers cleared. Customers happy.â€*\
Silenceâ€”good silenceâ€”fills the room. Juana exhales. Hector merely nods.

Wanjiru turns to Katherine: â€œWe didnâ€™t *see* the problem because we never asked the system to speak.â€\
Katherine replies: â€œFrom now on, telemetry first, feature second.â€

:::learner reflection
List two concrete CI checks you can add *today* that guarantee traces and logs remain correlated after every deploy.
:::

### Image Embed

![Alt text](images/panel8_team_realization.png){width=640}

:::hector quote
**Hector says:** â€œYouâ€™re not done when the code worksâ€”youâ€™re done when the code confesses.â€
:::

______________________________________________________________________

## Panel 9 â€“ **Closing Shot**

### ğŸ¯ Learning Objective

Anchor the chapterâ€™s moral: observability is the *contract* between teams and truth.

### âœ… Takeaway

A bankâ€™s *source of truth* must include its telemetryâ€”or the statements are forged.

### ğŸš¦ Applied Example â€” CI/CD Summary Badge

```text
âœ… Telemetry Gate: PASS | trace-coverage = 97 %
```

### Teaching Narrative

The scene widens: dawn over Nairobi HQ, server-room lights dimmed, dashboards quiet. Hector locks the incident whiteboard, flips it to a clean slate, and addresses the learners:

> â€œToday you watched a system lie through omission. You fixed the lie by giving it a louder mouth. Next time, make the mouth *before* the lie.â€

He tosses a marker into a mug, grabs his RHEL cap, and heads for the exit.

:::sre wisdom box
**SRE Wisdom:** â€œIf telemetry isnâ€™t in the definition of done, neither is reliability.â€
:::

### Image Embed

![Alt text](images/panel9_closing_shot.png){width=640}

:::hector quote
**Hectorâ€™s Closing Line:** â€œRememberâ€”if the problem canâ€™t be *seen*, the problem will be *you*.â€
:::

______________________________________________________________________
